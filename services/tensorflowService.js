const tf = require('@tensorflow/tfjs-node');
const Result = require('../models/Result');
const NNPrediction = require('../models/NNPrediction');
const NNState = require('../models/NNState');
const AdvancedFeatureEngineer = require('./advancedFeatureService');
const FeatureEngineeringService = require('./featureEngineeringService');
const { DateTime } = require('luxon');

const NN_MODEL_NAME = 'GDB_LSTM_TFJS_PREMIUM_V1';
const SEQUENCE_LENGTH = 7;
const OUTPUT_NODES = 50;
const EPOCHS = 50;
const BATCH_SIZE = 32;

class TensorFlowService {
  constructor() {
    this.model = null;
    this.featureService = new FeatureEngineeringService();
    this.advancedFeatureEngineer = new AdvancedFeatureEngineer();
    this.inputNodes = 0;
  }

  async buildModel(inputNodes) {
    console.log(`üèóÔ∏è X√¢y d·ª±ng model v·ªõi ${inputNodes} features...`);
    this.inputNodes = inputNodes;

    const model = tf.sequential();

    // L·ªöP ƒê·∫¶U TI√äN: GI·∫¢M ƒê∆†N GI·∫¢N H√ìA
    model.add(tf.layers.lstm({
        units: 32,  // GI·∫¢M XU·ªêNG 32
        returnSequences: false, // KH√îNG return sequences ƒë·ªÉ gi·∫£m ƒë·ªô ph·ª©c t·∫°p
        inputShape: [SEQUENCE_LENGTH, inputNodes],
        kernelInitializer: 'glorotNormal', // Initializer ·ªïn ƒë·ªãnh h∆°n
        recurrentInitializer: 'orthogonal',
        kernelRegularizer: tf.regularizers.l2({l2: 0.001}), // Gi·∫£m regularization
        recurrentRegularizer: tf.regularizers.l2({l2: 0.001}),
        // TH√äM gradient clipping ·ªü c·∫•p ƒë·ªô layer
        kernelConstraint: tf.constraints.maxNorm({maxValue: 1}),
        recurrentConstraint: tf.constraints.maxNorm({maxValue: 1})
    }));

    model.add(tf.layers.batchNormalization());
    model.add(tf.layers.dropout({rate: 0.2})); // Gi·∫£m dropout
    
    model.add(tf.layers.dense({
        units: 16,  // GI·∫¢M XU·ªêNG 16
        activation: 'relu',
        kernelInitializer: 'glorotNormal',
        kernelRegularizer: tf.regularizers.l2({l2: 0.001})
    }));

    model.add(tf.layers.dense({
        units: OUTPUT_NODES,
        activation: 'sigmoid',
        kernelInitializer: 'glorotNormal'
    }));
    
    model.summary();

    // COMPILE V·ªöI C√ÄI ƒê·∫∂T AN TO√ÄN H∆†N
    const optimizer = tf.train.adam(0.0005); // Learning rate nh·ªè h∆°n
    
    model.compile({
    optimizer: tf.train.adam(0.0005),
    loss: 'meanSquaredError', // TH·ª¨ H√ÄM LOSS KH√ÅC
    metrics: []
});

    this.model = model;
    return this.model;
}

  async trainModel(trainingData) {
    const { inputs, targets } = trainingData;
    
    console.log('üîç Ki·ªÉm tra cu·ªëi c√πng tr∆∞·ªõc khi training:');
    console.log('- Inputs length:', inputs.length);
    console.log('- Targets length:', targets.length);
    
    const inputTensor = tf.tensor3d(inputs, [inputs.length, SEQUENCE_LENGTH, this.inputNodes]);
    const targetTensor = tf.tensor2d(targets, [targets.length, OUTPUT_NODES]);

    // S·ª¨ D·ª§NG OPTIMIZER V·ªöI GRADIENT CLIPPING
    const optimizer = tf.train.adam(0.0005);
    
    // C·∫¨P NH·∫¨T OPTIMIZER CHO MODEL
    this.model.compile({
        optimizer: optimizer,
        loss: 'binaryCrossentropy',
        metrics: []
    });

    const history = await this.model.fit(inputTensor, targetTensor, {
        epochs: EPOCHS,
        batchSize: Math.min(BATCH_SIZE, inputs.length), // ƒê·∫£m b·∫£o batch size kh√¥ng qu√° l·ªõn
        validationSplit: 0.1,
        callbacks: {
            onEpochEnd: (epoch, logs) => {
                if (isNaN(logs.loss)) {
                    console.error('‚ùå NaN loss detected! Stopping training.');
                    this.model.stopTraining = true;
                    console.log('üìä Debug info:', {
                        epoch,
                        inputShape: inputTensor.shape,
                        targetShape: targetTensor.shape
                    });
                } else {
                    console.log(`Epoch ${epoch + 1}: Loss = ${logs.loss.toFixed(4)}`);
                }
            }
        }
    });

    inputTensor.dispose();
    targetTensor.dispose();

    return history;
}

  async predict(inputSequence) {
    const inputTensor = tf.tensor3d([inputSequence], [1, SEQUENCE_LENGTH, this.inputNodes]);
    const prediction = this.model.predict(inputTensor);
    const output = await prediction.data();
    prediction.dispose();
    inputTensor.dispose();
    return Array.from(output);
  }

  prepareTarget(gdbString) {
    const target = Array(OUTPUT_NODES).fill(0);
    gdbString.split('').forEach((digit, index) => {
      const d = parseInt(digit);
      if (!isNaN(d) && index < 5) {
        target[index * 10 + d] = 0.99;
      }
    });
    return target;
  }

  async prepareTrainingData() {
    console.log('üìù B·∫Øt ƒë·∫ßu chu·∫©n b·ªã d·ªØ li·ªáu hu·∫•n luy·ªán...');
    const results = await Result.find().sort({ 'ngay': 1 }).lean();
    // KI·ªÇM TRA T√çNH ·ªîN ƒê·ªäNH C·ª¶A FEATURES
const featureStabilityCheck = (features) => {
    const mean = features.reduce((a, b) => a + b, 0) / features.length;
    const variance = features.reduce((a, b) => a + Math.pow(b - mean, 2), 0) / features.length;
    const std = Math.sqrt(variance);
    
    console.log(`üìä Feature stability - Mean: ${mean.toFixed(4)}, Std: ${std.toFixed(4)}`);
    
    // N·∫øu std qu√° th·∫•p, c√≥ th·ªÉ features kh√¥ng ƒëa d·∫°ng
    if (std < 0.01) {
        console.warn('‚ö†Ô∏è Feature std qu√° th·∫•p, c√≥ th·ªÉ c·∫ßn ƒëa d·∫°ng h√≥a features');
    }
};

if (trainingData.length > 0) {
    const sampleFeatures = trainingData[0].inputSequence.flat();
    featureStabilityCheck(sampleFeatures);
    
    this.inputNodes = trainingData[0].inputSequence[0].length;
    console.log(`‚úÖ ƒê√£ chu·∫©n b·ªã ${trainingData.length} chu·ªói d·ªØ li·ªáu h·ª£p l·ªá`);
}
    console.log(`üìä T·ªïng s·ªë b·∫£n ghi trong DB: ${results.length}`);
    console.log('üìã 5 b·∫£n ghi ƒë·∫ßu ti√™n:', results.slice(0, 5).map(r => ({ ngay: r.ngay, giai: r.giai, so: r.so })));

    if (results.length < SEQUENCE_LENGTH + 1) {
      throw new Error(`Kh√¥ng ƒë·ªß d·ªØ li·ªáu. C·∫ßn √≠t nh·∫•t ${SEQUENCE_LENGTH + 1} ng√†y.`);
    }

    const grouped = {};
    results.forEach(r => {
      if (!grouped[r.ngay]) grouped[r.ngay] = [];
      grouped[r.ngay].push(r);
    });

    const days = Object.keys(grouped).sort((a, b) => this.dateKey(a).localeCompare(this.dateKey(b)));
    const trainingData = [];

    console.log(`üìÖ T·ªïng s·ªë ng√†y c√≥ d·ªØ li·ªáu: ${days.length}`);
    console.log('üìÖ 5 ng√†y ƒë·∫ßu:', days.slice(0, 5));

    for (let i = 0; i < days.length - SEQUENCE_LENGTH; i++) {
      const sequenceDaysStrings = days.slice(i, i + SEQUENCE_LENGTH);
      const targetDayString = days[i + SEQUENCE_LENGTH];
      
      const inputSequence = [];
      let sequenceValid = true;

      for(let j = 0; j < SEQUENCE_LENGTH; j++) {
        const currentDayForFeature = grouped[sequenceDaysStrings[j]] || [];
        const dateStr = sequenceDaysStrings[j];
        
        const previousDaysForBasicFeatures = days.slice(0, i + j).map(day => grouped[day] || []);
        const previousDaysForAdvancedFeatures = previousDaysForBasicFeatures.slice().reverse();

        const basicFeatures = this.featureService.extractAllFeatures(currentDayForFeature, previousDaysForBasicFeatures, dateStr);
        const advancedFeatures = this.advancedFeatureEngineer.extractPremiumFeatures(currentDayForFeature, previousDaysForAdvancedFeatures);
        
        let finalFeatureVector = [...basicFeatures, ...Object.values(advancedFeatures).flat()];
        
        const hasInvalid = finalFeatureVector.some(val => 
          isNaN(val) || val === null || val === undefined || !isFinite(val)
        );
        
        if (hasInvalid) {
          console.error(`‚ùå D·ªØ li·ªáu kh√¥ng h·ª£p l·ªá ·ªü ng√†y ${dateStr}:`, {
            basicFeatures: basicFeatures.some(v => isNaN(v)),
            advancedFeatures: Object.values(advancedFeatures).flat().some(v => isNaN(v)),
            finalVector: finalFeatureVector.filter(v => isNaN(v)).length
          });
          sequenceValid = false;
          break;
        }
        
        const EXPECTED_SIZE = 346;
        if (finalFeatureVector.length !== EXPECTED_SIZE) {
          console.warn(`‚ö†Ô∏è ƒêi·ªÅu ch·ªânh k√≠ch th∆∞·ªõc feature vector: ${finalFeatureVector.length} -> ${EXPECTED_SIZE}`);
          if (finalFeatureVector.length > EXPECTED_SIZE) {
            finalFeatureVector = finalFeatureVector.slice(0, EXPECTED_SIZE);
          } else {
            finalFeatureVector = [...finalFeatureVector, ...Array(EXPECTED_SIZE - finalFeatureVector.length).fill(0)];
          }
        }
        
        inputSequence.push(finalFeatureVector);
      }

      if (!sequenceValid) continue;

      const targetGDB = (grouped[targetDayString] || []).find(r => r.giai === 'ƒêB');
      if (targetGDB?.so && String(targetGDB.so).length >= 5) {
        const targetGDBString = String(targetGDB.so).padStart(5, '0');
        const targetArray = this.prepareTarget(targetGDBString);

        const invalidTargets = targetArray.filter(val => isNaN(val) || val === null || val === undefined);
        if (invalidTargets.length > 0) {
          console.error(`‚ùå Target kh√¥ng h·ª£p l·ªá cho ng√†y ${targetDayString}:`, invalidTargets.length);
          continue;
        }

        trainingData.push({ inputSequence, targetArray });
      }
    }

    // DEBUG CHI TI·∫æT
if (trainingData.length > 0) {
  console.log('üîç DEBUG - Ki·ªÉm tra d·ªØ li·ªáu training:');
  console.log(`- S·ªë chu·ªói: ${trainingData.length}`);
  console.log(`- K√≠ch th∆∞·ªõc input sequence: ${trainingData[0].inputSequence.length}`);
  console.log(`- K√≠ch th∆∞·ªõc feature vector: ${trainingData[0].inputSequence[0].length}`);
  
  // THAY TH·∫æ flatMap B·∫∞NG V√íNG L·∫∂P TH√îNG TH∆Ø·ªúNG ƒê·ªÇ TR√ÅNH TR√ÄN STACK
  let allFeatures = [];
  let allTargets = [];
  
  // S·ª≠ d·ª•ng v√≤ng l·∫∑p thay v√¨ flatMap ƒë·ªÉ tr√°nh tr√†n stack
  for (let i = 0; i < trainingData.length; i++) {
    const data = trainingData[i];
    
    // X·ª≠ l√Ω features
    for (let j = 0; j < data.inputSequence.length; j++) {
      allFeatures = allFeatures.concat(data.inputSequence[j]);
    }
    
    // X·ª≠ l√Ω targets
    allTargets = allTargets.concat(data.targetArray);
  }
  
  // Ki·ªÉm tra min/max an to√†n h∆°n
  let featuresMin = Infinity, featuresMax = -Infinity;
  let targetsMin = Infinity, targetsMax = -Infinity;
  
  for (let i = 0; i < allFeatures.length; i++) {
    const val = allFeatures[i];
    if (val < featuresMin) featuresMin = val;
    if (val > featuresMax) featuresMax = val;
  }
  
  for (let i = 0; i < allTargets.length; i++) {
    const val = allTargets[i];
    if (val < targetsMin) targetsMin = val;
    if (val > targetsMax) targetsMax = val;
  }
  
  console.log(`- Features - Min: ${featuresMin}, Max: ${featuresMax}`);
  console.log(`- Targets - Min: ${targetsMin}, Max: ${targetsMax}`);
  
  // Ki·ªÉm tra NaN an to√†n h∆°n
  let nanFeaturesCount = 0;
  let nanTargetsCount = 0;
  
  for (let i = 0; i < allFeatures.length; i++) {
    if (isNaN(allFeatures[i])) nanFeaturesCount++;
  }
  
  for (let i = 0; i < allTargets.length; i++) {
    if (isNaN(allTargets[i])) nanTargetsCount++;
  }
  
  console.log(`- NaN trong features: ${nanFeaturesCount}`);
  console.log(`- NaN trong targets: ${nanTargetsCount}`);
  
  this.inputNodes = trainingData[0].inputSequence[0].length;
  console.log(`‚úÖ ƒê√£ chu·∫©n b·ªã ${trainingData.length} chu·ªói d·ªØ li·ªáu h·ª£p l·ªá`);
} else {
  throw new Error("‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu training h·ª£p l·ªá sau khi ki·ªÉm tra.");
}

    return trainingData;
  }

  dateKey(s) {
    if (!s || typeof s !== 'string') return '';
    const parts = s.split('/');
    return parts.length !== 3 ? s : `${parts[2]}-${parts[1].padStart(2, '0')}-${parts[0].padStart(2, '0')}`;
  }

  async saveModel() {
    if (!this.model) {
      throw new Error('No model to save');
    }
    const modelInfo = {
      modelName: NN_MODEL_NAME,
      inputNodes: this.inputNodes,
      savedAt: new Date().toISOString()
    };
    
    const saveResult = await this.model.save('file://./models/tfjs_model');
   
    await NNState.findOneAndUpdate(
      { modelName: NN_MODEL_NAME },
      {
        state: modelInfo,
        modelArtifacts: saveResult
      },
      { upsert: true }
    );
    console.log(`üíæ TensorFlow model saved v·ªõi ${this.inputNodes} input nodes`);
  }

  async loadModel() {
    const modelState = await NNState.findOne({ modelName: NN_MODEL_NAME });
    if (modelState && modelState.modelArtifacts) {
      this.model = await tf.loadLayersModel('file://./models/tfjs_model/model.json');
      this.inputNodes = modelState.state.inputNodes;
      console.log(`‚úÖ TensorFlow model loaded v·ªõi ${this.inputNodes} input nodes`);
      return true;
    }
    return false;
  }

  async runHistoricalTraining() {
    console.log('üîî [TensorFlow Service] B·∫Øt ƒë·∫ßu Hu·∫•n luy·ªán L·ªãch s·ª≠ v·ªõi ki·∫øn tr√∫c Premium...');
   
    const trainingData = await this.prepareTrainingData();
    if (trainingData.length === 0 || trainingData.some(d => d.inputSequence.length !== SEQUENCE_LENGTH || d.inputSequence.flat().some(isNaN))) {
      throw new Error('D·ªØ li·ªáu training r·ªóng ho·∫∑c ch·ª©a gi√° tr·ªã kh√¥ng h·ª£p l·ªá. Ki·ªÉm tra DB v√† feature engineering.');
    }
    
    const inputs = trainingData.map(d => d.inputSequence);
    const targets = trainingData.map(d => d.targetArray);
    
    await this.buildModel(this.inputNodes);
    
    this.model.compile({
      optimizer: tf.train.adam({learningRate: 0.0005}),
      loss: 'binaryCrossentropy',
      metrics: []
    });
    
    console.log('‚úÖ Model ƒë√£ ƒë∆∞·ª£c compile. B·∫Øt ƒë·∫ßu qu√° tr√¨nh training...');
    
    await this.trainModel({ inputs, targets });
   
    await this.saveModel();
    
    return {
      message: `Hu·∫•n luy·ªán Premium Model ho√†n t·∫•t. ƒê√£ x·ª≠ l√Ω ${trainingData.length} chu·ªói, ${EPOCHS} epochs.`,
      sequences: trainingData.length,
      epochs: EPOCHS,
      featureSize: this.inputNodes,
      modelName: NN_MODEL_NAME
    };
  }

  async runLearning() {
    console.log('üîî [TensorFlow Service] Learning from new results...');
  
    if (!this.model) {
      const modelLoaded = await this.loadModel();
      if (!modelLoaded) {
        throw new Error('Model ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán. H√£y ch·∫°y hu·∫•n luy·ªán l·ªãch s·ª≠ tr∆∞·ªõc.');
      }
    }
    
    const predictionsToLearn = await NNPrediction.find({ danhDauDaSo: false }).lean();
    if (predictionsToLearn.length === 0) {
      return { message: 'Kh√¥ng c√≥ d·ª± ƒëo√°n m·ªõi n√†o ƒë·ªÉ h·ªçc.' };
    }
    
    const results = await Result.find().sort({ 'ngay': 1 }).lean();
    const grouped = {};
    results.forEach(r => {
      if (!grouped[r.ngay]) grouped[r.ngay] = [];
      grouped[r.ngay].push(r);
    });
    
    const days = Object.keys(grouped).sort((a, b) => this.dateKey(a).localeCompare(this.dateKey(b)));
  
    let learnedCount = 0;
    const trainingData = [];
    
    for (const pred of predictionsToLearn) {
      const targetDayStr = pred.ngayDuDoan;
      const targetDayIndex = days.indexOf(targetDayStr);

      if (targetDayIndex >= SEQUENCE_LENGTH) {
        const actualResult = (grouped[targetDayStr] || []).find(r => r.giai === 'ƒêB');
        
        if (actualResult?.so && String(actualResult.so).length >= 5) {
          const sequenceDays = days.slice(targetDayIndex - SEQUENCE_LENGTH, targetDayIndex);
          const previousDays = [];
          const inputSequence = sequenceDays.map(day => {
            const dayResults = grouped[day] || [];
            const prevDays = previousDays.slice();
            previousDays.push(dayResults);
            return this.featureService.extractAllFeatures(dayResults, prevDays, day);
          });

          const targetGDBString = String(actualResult.so).padStart(5, '0');
          const targetArray = this.prepareTarget(targetGDBString);
          
          trainingData.push({ inputSequence, targetArray });
          learnedCount++;
        }
      }
      
      await NNPrediction.updateOne({ _id: pred._id }, { danhDauDaSo: true });
    }

    if (trainingData.length > 0) {
      const inputs = trainingData.map(d => d.inputSequence);
      const targets = trainingData.map(d => d.targetArray);

      const inputTensor = tf.tensor3d(inputs, [inputs.length, SEQUENCE_LENGTH, this.inputNodes]);
      const targetTensor = tf.tensor2d(targets, [targets.length, OUTPUT_NODES]);

      await this.model.fit(inputTensor, targetTensor, {
        epochs: 3,
        batchSize: Math.min(BATCH_SIZE, inputs.length),
        validationSplit: 0.1
      });

      inputTensor.dispose();
      targetTensor.dispose();

      await this.saveModel();
    }
  
    return { message: `TensorFlow LSTM ƒë√£ h·ªçc xong. ƒê√£ x·ª≠ l√Ω ${learnedCount} k·∫øt qu·∫£ m·ªõi.` };
  }

  async runNextDayPrediction() {
    console.log('üîî [TensorFlow Service] Generating next day prediction...');
    
    if (!this.model) {
      const modelLoaded = await this.loadModel();
      if (!modelLoaded) {
        throw new Error('Model ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán. H√£y ch·∫°y hu·∫•n luy·ªán tr∆∞·ªõc.');
      }
    }

    const results = await Result.find().lean();
    if (results.length < SEQUENCE_LENGTH) {
      throw new Error(`Kh√¥ng ƒë·ªß d·ªØ li·ªáu. C·∫ßn √≠t nh·∫•t ${SEQUENCE_LENGTH} ng√†y.`);
    }

    const grouped = {};
    results.forEach(r => {
      if (!grouped[r.ngay]) grouped[r.ngay] = [];
      grouped[r.ngay].push(r);
    });

    const days = Object.keys(grouped).sort((a, b) => this.dateKey(a).localeCompare(this.dateKey(b)));
    const latestSequenceDays = days.slice(-SEQUENCE_LENGTH);

    const previousDays = [];
    const inputSequence = latestSequenceDays.map(day => {
      const dayResults = grouped[day] || [];
      const prevDays = previousDays.slice();
      previousDays.push(dayResults);
      return this.featureService.extractAllFeatures(dayResults, prevDays, day);
    });

    const output = await this.predict(inputSequence);
    const prediction = this.decodeOutput(output);

    const latestDay = latestSequenceDays[latestSequenceDays.length - 1];
    const nextDayStr = DateTime.fromFormat(latestDay, 'dd/MM/yyyy').plus({ days: 1 }).toFormat('dd/MM/yyyy');

    await NNPrediction.findOneAndUpdate(
      { ngayDuDoan: nextDayStr },
      { ngayDuDoan: nextDayStr, ...prediction, danhDauDaSo: false },
      { upsert: true, new: true }
    );

    return {
      message: `TensorFlow LSTM ƒë√£ t·∫°o d·ª± ƒëo√°n cho ng√†y ${nextDayStr}.`,
      ngayDuDoan: nextDayStr
    };
  }

  decodeOutput(output) {
    const prediction = { pos1: [], pos2: [], pos3: [], pos4: [], pos5: [] };
    for (let i = 0; i < 5; i++) {
      const positionOutput = output.slice(i * 10, (i + 1) * 10);
      const digitsWithValues = positionOutput
        .map((value, index) => ({ digit: String(index), value }))
        .sort((a, b) => b.value - a.value)
        .slice(0, 5)
        .map(item => item.digit);
      prediction[`pos${i + 1}`] = digitsWithValues;
    }
    return prediction;
  }
}

module.exports = TensorFlowService;
