const tf = require('@tensorflow/tfjs-node');
const Result = require('../models/Result');
const NNPrediction = require('../models/NNPrediction');
const NNState = require('../models/NNState');
const AdvancedFeatureEngineer = require('./advancedFeatureService');
const FeatureEngineeringService = require('./featureEngineeringService');
const { DateTime } = require('luxon');
const NN_MODEL_NAME = 'GDB_LSTM_TFJS_PREMIUM_V1'; // Äá»•i tÃªn model Ä‘á»ƒ lÆ°u tráº¡ng thÃ¡i má»›i
const SEQUENCE_LENGTH = 7;
const OUTPUT_NODES = 50;
const EPOCHS = 50; // CÃ³ thá»ƒ tÄƒng lÃªn 70-100 vá»›i model phá»©c táº¡p hÆ¡n
const BATCH_SIZE = 32;
class TensorFlowService {
Â Â constructor() {
Â Â Â Â this.model = null;
Â Â Â Â this.featureService = new FeatureEngineeringService();
Â Â Â Â this.advancedFeatureEngineer = new AdvancedFeatureEngineer();
Â Â Â Â this.inputNodes = 0;
Â Â }
Â Â async buildModel(inputNodes) {
Â Â Â Â console.log(ğŸ—ï¸ Báº¯t Ä‘áº§u xÃ¢y dá»±ng kiáº¿n trÃºc Premium Model vá»›i ${inputNodes} features...);
Â Â Â Â this.inputNodes = inputNodes;
Â Â Â Â const model = tf.sequential();
Â Â Â Â // --- Táº¦NG 1: Lá»šP LSTM CHÃNH ---
Â Â Â Â // Nhiá»‡m vá»¥: Xá»­ lÃ½ trá»±c tiáº¿p chuá»—i 7 ngÃ y x 346 features. Lá»›p nÃ y há»c cÃ¡c máº«u hÃ¬nh thá»i gian (temporal patterns) á»Ÿ má»©c Ä‘á»™ tháº¥p.
Â Â Â Â model.add(tf.layers.lstm({
Â Â Â Â Â Â units: 192, // Sá»‘ lÆ°á»£ng nÆ¡-ron (bá»™ nhá»›) trong lá»›p LSTM. 192 lÃ  má»™t con sá»‘ lá»›n, phÃ¹ há»£p vá»›i lÆ°á»£ng features Ä‘áº§u vÃ o cao.
Â Â Â Â Â Â returnSequences: true, // Ráº¥t QUAN TRá»ŒNG. Äáº·t lÃ  true Ä‘á»ƒ output cá»§a lá»›p nÃ y váº«n lÃ  má»™t chuá»—i (sequence), lÃ m Ä‘áº§u vÃ o cho lá»›p LSTM tiáº¿p theo.
Â Â Â Â Â Â inputShape: [SEQUENCE_LENGTH, inputNodes], // Äá»‹nh nghÄ©a hÃ¬nh dáº¡ng Ä‘áº§u vÃ o: 7 bÆ°á»›c thá»i gian, má»—i bÆ°á»›c cÃ³ inputNodes features.
Â Â Â Â Â Â kernelRegularizer: tf.regularizers.l2({l2: 0.001}), // Ká»¹ thuáº­t chÃ­nh quy hÃ³a L2: "Pháº¡t" cÃ¡c trá»ng sá»‘ (weights) cÃ³ giÃ¡ trá»‹ quÃ¡ lá»›n, buá»™c mÃ´ hÃ¬nh pháº£i há»c cÃ¡c máº«u hÃ¬nh tá»•ng quÃ¡t hÆ¡n thay vÃ¬ dá»±a dáº«m vÃ o má»™t vÃ i features. GiÃºp chá»‘ng overfitting.
Â Â Â Â Â Â recurrentRegularizer: tf.regularizers.l2({l2: 0.001}) // TÆ°Æ¡ng tá»± L2 nhÆ°ng Ã¡p dá»¥ng cho cÃ¡c trá»ng sá»‘ káº¿t ná»‘i ná»™i bá»™ (recurrent connections) cá»§a LSTM.
Â Â Â Â }));
Â Â Â Â // --- Lá»šP á»”N Äá»ŠNH HÃ“A ---
Â Â Â Â // Nhiá»‡m vá»¥: Chuáº©n hÃ³a output cá»§a lá»›p LSTM trÃªn, giÃºp quÃ¡ trÃ¬nh há»c á»Ÿ cÃ¡c lá»›p sau diá»…n ra nhanh vÃ  á»•n Ä‘á»‹nh hÆ¡n.
Â Â Â Â model.add(tf.layers.batchNormalization());
Â Â Â Â // --- Lá»šP LOáº I Bá» (DROPOUT) ---
Â Â Â Â // Nhiá»‡m vá»¥: Chá»‘ng overfitting. Trong má»—i lÆ°á»£t training, nÃ³ sáº½ ngáº«u nhiÃªn "táº¯t" 25% cÃ¡c nÆ¡-ron, buá»™c cÃ¡c nÆ¡-ron cÃ²n láº¡i pháº£i há»c má»™t cÃ¡ch Ä‘á»™c láº­p vÃ  máº¡nh máº½ hÆ¡n.
Â Â Â Â model.add(tf.layers.dropout({rate: 0.25}));
Â Â Â Â // --- Táº¦NG 2: Lá»šP LSTM THá»¨ HAI ---
Â Â Â Â // Nhiá»‡m vá»¥: Nháº­n chuá»—i output tá»« táº§ng 1 vÃ  há»c cÃ¡c máº«u hÃ¬nh á»Ÿ má»©c cao hÆ¡n ("máº«u hÃ¬nh cá»§a cÃ¡c máº«u hÃ¬nh").
Â Â Â Â model.add(tf.layers.lstm({
Â Â Â Â Â Â units: 96, // Sá»‘ units cÃ³ thá»ƒ giáº£m dáº§n á»Ÿ cÃ¡c lá»›p sau vÃ¬ thÃ´ng tin Ä‘Ã£ Ä‘Æ°á»£c trá»«u tÆ°á»£ng hÃ³a.
Â Â Â Â Â Â returnSequences: false, // QUAN TRá»ŒNG. Äáº·t lÃ  false vÃ¬ Ä‘Ã¢y lÃ  lá»›p LSTM cuá»‘i cÃ¹ng. Output cá»§a nÃ³ sáº½ lÃ  má»™t vector duy nháº¥t (kÃ­ch thÆ°á»›c 96) Ä‘áº¡i diá»‡n cho toÃ n bá»™ chuá»—i, sáºµn sÃ ng Ä‘á»ƒ Ä‘Æ°a vÃ o cÃ¡c lá»›p Dense.
Â Â Â Â Â Â kernelRegularizer: tf.regularizers.l2({l2: 0.001}),
Â Â Â Â Â Â recurrentRegularizer: tf.regularizers.l2({l2: 0.001})
Â Â Â Â }));
Â Â Â Â model.add(tf.layers.batchNormalization());
Â Â Â Â model.add(tf.layers.dropout({rate: 0.25}));
Â Â Â 
Â Â Â Â // --- Táº¦NG 3: Lá»šP Káº¾T Ná»I Äáº¦Y Äá»¦ (DENSE) ---
Â Â Â Â // Nhiá»‡m vá»¥: Hoáº¡t Ä‘á»™ng nhÆ° má»™t lá»›p phÃ¢n loáº¡i cuá»‘i cÃ¹ng, káº¿t há»£p cÃ¡c features báº­c cao Ä‘Ã£ Ä‘Æ°á»£c há»c bá»Ÿi cÃ¡c lá»›p LSTM Ä‘á»ƒ Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh.
Â Â Â Â model.add(tf.layers.dense({
Â Â Â Â Â Â units: 48,
Â Â Â Â Â Â activation: 'relu', // HÃ m kÃ­ch hoáº¡t 'relu' (Rectified Linear Unit) ráº¥t phá»• biáº¿n vÃ  hiá»‡u quáº£, giÃºp mÃ´ hÃ¬nh há»c cÃ¡c má»‘i quan há»‡ phi tuyáº¿n.
Â Â Â Â Â Â kernelRegularizer: tf.regularizers.l2({l2: 0.001})
Â Â Â Â }));
Â Â Â Â // --- Táº¦NG 4: Lá»šP OUTPUT CUá»I CÃ™NG ---
Â Â Â Â // Nhiá»‡m vá»¥: ÄÆ°a ra dá»± Ä‘oÃ¡n cuá»‘i cÃ¹ng.
Â Â Â Â model.add(tf.layers.dense({
Â Â Â Â Â Â units: OUTPUT_NODES, // 50 units (5 vá»‹ trÃ­ * 10 chá»¯ sá»‘).
Â Â Â Â Â Â activation: 'sigmoid' // HÃ m kÃ­ch hoáº¡t 'sigmoid' Ã©p cÃ¡c giÃ¡ trá»‹ output vá» khoáº£ng [0, 1]. Ráº¥t phÃ¹ há»£p cho bÃ i toÃ¡n phÃ¢n loáº¡i Ä‘a nhÃ£n (multi-label classification) nÃ y, vÃ¬ má»—i output Ä‘áº¡i diá»‡n cho "xÃ¡c suáº¥t" má»™t chá»¯ sá»‘ xuáº¥t hiá»‡n á»Ÿ má»™t vá»‹ trÃ­.
Â Â Â Â }));
Â Â Â 
Â Â Â Â // In ra cáº¥u trÃºc cá»§a model Ä‘á»ƒ kiá»ƒm tra.
Â Â Â Â model.summary();
Â Â Â Â this.model = model;
Â Â Â Â return this.model;
Â Â }
Â Â async trainModel(trainingData) {
Â Â const { inputs, targets } = trainingData;
Â 
Â Â // THÃŠM KIá»‚M TRA Dá»® LIá»†U Ká»¸ LÆ¯á» NG
Â Â if (!inputs || !targets || inputs.length === 0 || targets.length === 0) {
Â Â Â Â throw new Error('Dá»¯ liá»‡u training rá»—ng hoáº·c khÃ´ng há»£p lá»‡');
Â Â }
Â Â // KIá»‚M TRA Tá»ªNG PHáº¦N Tá»¬
Â Â inputs.forEach((input, idx) => {
Â Â Â Â if (!input || input.length !== SEQUENCE_LENGTH) {
Â Â Â Â Â Â throw new Error(Input táº¡i index ${idx} khÃ´ng há»£p lá»‡: ${input});
Â Â Â Â }
Â Â });
Â Â targets.forEach((target, idx) => {
Â Â Â Â if (!target || target.length !== OUTPUT_NODES) {
Â Â Â Â Â Â throw new Error(Target táº¡i index ${idx} khÃ´ng há»£p lá»‡: ${target});
Â Â Â Â }
Â Â });
Â Â const inputTensor = tf.tensor3d(inputs, [inputs.length, SEQUENCE_LENGTH, this.inputNodes]);
Â Â const targetTensor = tf.tensor2d(targets, [targets.length, OUTPUT_NODES]);
Â Â // THÃŠM KIá»‚M TRA TENSOR
Â Â if (inputTensor.shape.some(dim => dim === 0) || targetTensor.shape.some(dim => dim === 0)) {
Â Â Â Â throw new Error('Tensor cÃ³ shape khÃ´ng há»£p lá»‡');
Â Â }
Â Â const history = await this.model.fit(inputTensor, targetTensor, {
Â Â Â Â epochs: EPOCHS,
Â Â Â Â batchSize: BATCH_SIZE,
Â Â Â Â validationSplit: 0.1,
Â Â Â Â callbacks: {
Â Â Â Â Â Â onEpochEnd: (epoch, logs) => {
Â Â Â Â Â Â Â Â if (isNaN(logs.loss)) {
Â Â Â Â Â Â Â Â Â Â console.error('NaN loss detected! Stopping training.');
Â Â Â Â Â Â Â Â Â Â this.model.stopTraining = true;
Â Â Â Â Â Â Â Â }
Â Â Â Â Â Â Â Â console.log(Epoch ${epoch + 1}: Loss = ${logs.loss.toFixed(4)});
Â Â Â Â Â Â }
Â Â Â Â }
Â Â });
Â Â inputTensor.dispose();
Â Â targetTensor.dispose();
Â Â return history;
}
Â Â async predict(inputSequence) {
Â Â Â Â const inputTensor = tf.tensor3d([inputSequence], [1, SEQUENCE_LENGTH, this.inputNodes]);
Â Â Â Â const prediction = this.model.predict(inputTensor);
Â Â Â Â const output = await prediction.data();
Â Â Â Â prediction.dispose();
Â Â Â Â inputTensor.dispose();
Â Â Â Â return Array.from(output);
Â Â }
Â Â prepareTarget(gdbString) {
Â Â Â Â const target = Array(OUTPUT_NODES).fill(0);
// ... target[index * 10 + d] = 1;
Â Â Â Â gdbString.split('').forEach((digit, index) => {
Â Â Â Â Â Â const d = parseInt(digit);
Â Â Â Â Â Â if (!isNaN(d) && index < 5) {
Â Â Â Â Â Â Â Â target[index * 10 + d] = 0.99;
Â Â Â Â Â Â }
Â Â Â Â });
Â Â Â Â return target;
Â Â }
Â Â async prepareTrainingData() {
  console.log('ğŸ“ Báº¯t Ä‘áº§u chuáº©n bá»‹ dá»¯ liá»‡u huáº¥n luyá»‡n...');
  const results = await Result.find().sort({ 'ngay': 1 }).lean();
  
  // DEBUG: Kiá»ƒm tra dá»¯ liá»‡u gá»‘c
  console.log(`ğŸ“Š Tá»•ng sá»‘ báº£n ghi trong DB: ${results.length}`);
  console.log('ğŸ“‹ 5 báº£n ghi Ä‘áº§u tiÃªn:', results.slice(0, 5).map(r => ({ ngay: r.ngay, giai: r.giai, so: r.so })));

  if (results.length < SEQUENCE_LENGTH + 1) {
    throw new Error(`KhÃ´ng Ä‘á»§ dá»¯ liá»‡u. Cáº§n Ã­t nháº¥t ${SEQUENCE_LENGTH + 1} ngÃ y.`);
  }

  const grouped = {};
  results.forEach(r => {
    if (!grouped[r.ngay]) grouped[r.ngay] = [];
    grouped[r.ngay].push(r);
  });

  const days = Object.keys(grouped).sort((a, b) => this.dateKey(a).localeCompare(this.dateKey(b)));
  const trainingData = [];

  console.log(`ğŸ“… Tá»•ng sá»‘ ngÃ y cÃ³ dá»¯ liá»‡u: ${days.length}`);
  console.log('ğŸ“… 5 ngÃ y Ä‘áº§u:', days.slice(0, 5));

  for (let i = 0; i < days.length - SEQUENCE_LENGTH; i++) {
    const sequenceDaysStrings = days.slice(i, i + SEQUENCE_LENGTH);
    const targetDayString = days[i + SEQUENCE_LENGTH];
    
    const inputSequence = [];
    let sequenceValid = true;

    for(let j = 0; j < SEQUENCE_LENGTH; j++) {
      const currentDayForFeature = grouped[sequenceDaysStrings[j]] || [];
      const dateStr = sequenceDaysStrings[j];
      
      const previousDaysForBasicFeatures = days.slice(0, i + j).map(day => grouped[day] || []);
      const previousDaysForAdvancedFeatures = previousDaysForBasicFeatures.slice().reverse();

      const basicFeatures = this.featureService.extractAllFeatures(currentDayForFeature, previousDaysForBasicFeatures, dateStr);
      const advancedFeatures = this.advancedFeatureEngineer.extractPremiumFeatures(currentDayForFeature, previousDaysForAdvancedFeatures);
      
      let finalFeatureVector = [...basicFeatures, ...Object.values(advancedFeatures).flat()];
      
      // KIá»‚M TRA Ká»¸ LÆ¯á» NG HÆ N
      const hasInvalid = finalFeatureVector.some(val => 
        isNaN(val) || val === null || val === undefined || !isFinite(val)
      );
      
      if (hasInvalid) {
        console.error(`âŒ Dá»¯ liá»‡u khÃ´ng há»£p lá»‡ á»Ÿ ngÃ y ${dateStr}:`, {
          basicFeatures: basicFeatures.some(v => isNaN(v)),
          advancedFeatures: Object.values(advancedFeatures).flat().some(v => isNaN(v)),
          finalVector: finalFeatureVector.filter(v => isNaN(v)).length
        });
        sequenceValid = false;
        break;
      }
      
      // Äáº¢M Báº¢O KÃCH THÆ¯á»šC CHUáº¨N
      const EXPECTED_SIZE = 346;
      if (finalFeatureVector.length !== EXPECTED_SIZE) {
        console.warn(`âš ï¸ Äiá»u chá»‰nh kÃ­ch thÆ°á»›c feature vector: ${finalFeatureVector.length} -> ${EXPECTED_SIZE}`);
        if (finalFeatureVector.length > EXPECTED_SIZE) {
          finalFeatureVector = finalFeatureVector.slice(0, EXPECTED_SIZE);
        } else {
          finalFeatureVector = [...finalFeatureVector, ...Array(EXPECTED_SIZE - finalFeatureVector.length).fill(0)];
        }
      }
      
      inputSequence.push(finalFeatureVector);
    }

    if (!sequenceValid) continue;

    const targetGDB = (grouped[targetDayString] || []).find(r => r.giai === 'ÄB');
    if (targetGDB?.so && String(targetGDB.so).length >= 5) {
      const targetGDBString = String(targetGDB.so).padStart(5, '0');
      const targetArray = this.prepareTarget(targetGDBString);

      // KIá»‚M TRA TARGET
      const invalidTargets = targetArray.filter(val => isNaN(val) || val === null || val === undefined);
      if (invalidTargets.length > 0) {
        console.error(`âŒ Target khÃ´ng há»£p lá»‡ cho ngÃ y ${targetDayString}:`, invalidTargets.length);
        continue;
      }

      trainingData.push({ inputSequence, targetArray });
    }
  }

  // DEBUG CHI TIáº¾T
  if (trainingData.length > 0) {
    console.log('ğŸ” DEBUG - Kiá»ƒm tra dá»¯ liá»‡u training:');
    console.log(`- Sá»‘ chuá»—i: ${trainingData.length}`);
    console.log(`- KÃ­ch thÆ°á»›c input sequence: ${trainingData[0].inputSequence.length}`);
    console.log(`- KÃ­ch thÆ°á»›c feature vector: ${trainingData[0].inputSequence[0].length}`);
    
    // Kiá»ƒm tra giÃ¡ trá»‹ min/max cá»§a features
    const allFeatures = trainingData.flatMap(d => d.inputSequence.flat());
    const allTargets = trainingData.flatMap(d => d.targetArray);
    
    console.log(`- Features - Min: ${Math.min(...allFeatures)}, Max: ${Math.max(...allFeatures)}`);
    console.log(`- Targets - Min: ${Math.min(...allTargets)}, Max: ${Math.max(...allTargets)}`);
    
    // Kiá»ƒm tra NaN
    const nanFeatures = allFeatures.filter(v => isNaN(v));
    const nanTargets = allTargets.filter(v => isNaN(v));
    console.log(`- NaN trong features: ${nanFeatures.length}`);
    console.log(`- NaN trong targets: ${nanTargets.length}`);
    
    this.inputNodes = trainingData[0].inputSequence[0].length;
    console.log(`âœ… ÄÃ£ chuáº©n bá»‹ ${trainingData.length} chuá»—i dá»¯ liá»‡u há»£p lá»‡`);
  } else {
    throw new Error("âŒ KhÃ´ng cÃ³ dá»¯ liá»‡u training há»£p lá»‡ sau khi kiá»ƒm tra.");
  }

  return trainingData;
}
Â Â async saveModel() {
Â Â Â Â if (!this.model) {
Â Â Â Â Â Â throw new Error('No model to save');
Â Â Â Â }
Â Â Â Â const modelInfo = {
Â Â Â Â Â Â modelName: NN_MODEL_NAME,
Â Â Â Â Â Â inputNodes: this.inputNodes,
Â Â Â Â Â Â savedAt: new Date().toISOString()
Â Â Â Â };
Â Â Â Â // LÆ°u model dÆ°á»›i dáº¡ng JSON (cÃ³ thá»ƒ lÆ°u vÃ o file hoáº·c database)
Â Â Â Â const saveResult = await this.model.save('file://./models/tfjs_model');
Â Â Â 
Â Â Â Â await NNState.findOneAndUpdate(
Â Â Â Â Â Â { modelName: NN_MODEL_NAME },
Â Â Â Â Â Â {
Â Â Â Â Â Â Â Â state: modelInfo,
Â Â Â Â Â Â Â Â modelArtifacts: saveResult
Â Â Â Â Â Â },
Â Â Â Â Â Â { upsert: true }
Â Â Â Â );
Â Â Â Â console.log(ğŸ’¾ TensorFlow model saved vá»›i ${this.inputNodes} input nodes);
Â Â }
Â Â async loadModel() {
Â Â Â Â const modelState = await NNState.findOne({ modelName: NN_MODEL_NAME });
Â Â Â Â if (modelState && modelState.modelArtifacts) {
Â Â Â Â Â Â this.model = await tf.loadLayersModel('file://./models/tfjs_model/model.json');
Â Â Â Â Â Â this.inputNodes = modelState.state.inputNodes;
Â Â Â Â Â Â console.log(âœ… TensorFlow model loaded vá»›i ${this.inputNodes} input nodes);
Â Â Â Â Â Â return true;
Â Â Â Â }
Â Â Â Â return false;
Â Â }
Â Â // =================================================================
Â Â // Cáº¬P NHáº¬T HÃ€M runHistoricalTraining Äá»‚ Sá»¬ Dá»¤NG MODEL Má»šI
Â Â // =================================================================
Â Â async runHistoricalTraining() {
Â Â Â 
Â Â Â Â console.log('ğŸ”” [TensorFlow Service] Báº¯t Ä‘áº§u Huáº¥n luyá»‡n Lá»‹ch sá»­ vá»›i kiáº¿n trÃºc Premium...');
Â Â Â 
Â Â Â Â const trainingData = await this.prepareTrainingData(); // HÃ m nÃ y Ä‘Ã£ Ä‘Æ°á»£c cáº­p nháº­t á»Ÿ BÆ°á»›c 1
Â Â Â Â if (trainingData.length === 0 || trainingData.some(d => d.inputSequence.length !== SEQUENCE_LENGTH || d.inputSequence.flat().some(isNaN))) {
Â Â Â Â throw new Error('Dá»¯ liá»‡u training rá»—ng hoáº·c chá»©a giÃ¡ trá»‹ khÃ´ng há»£p lá»‡. Kiá»ƒm tra DB vÃ  feature engineering.');
}
Â Â Â Â const inputs = trainingData.map(d => d.inputSequence);
Â Â Â Â const targets = trainingData.map(d => d.targetArray);
Â Â Â Â // XÃ¢y dá»±ng model má»›i dá»±a trÃªn sá»‘ features thá»±c táº¿
Â Â Â Â // this.inputNodes Ä‘Ã£ Ä‘Æ°á»£c cáº­p nháº­t trong prepareTrainingData
Â Â Â Â this.buildModel(this.inputNodes);
Â Â Â Â // COMPILE MODEL: Cáº¥u hÃ¬nh quÃ¡ trÃ¬nh há»c
Â Â Â Â this.model.compile({
Â Â optimizer: tf.train.adam({learningRate: 0.0005}),
Â Â loss: 'binaryCrossentropy',
Â Â // Táº M Bá» METRICS Äá»‚ DEBUG
Â Â // metrics: [tf.metrics.binaryAccuracy()]
Â Â metrics: [] // Bá» trá»‘ng Ä‘á»ƒ trÃ¡nh lá»—i
});
Â Â Â Â console.log('âœ… Model Ä‘Ã£ Ä‘Æ°á»£c compile. Báº¯t Ä‘áº§u quÃ¡ trÃ¬nh training...');
Â Â Â Â // Huáº¥n luyá»‡n model
Â Â Â Â await this.trainModel({ inputs, targets });
Â Â Â 
Â Â Â Â // LÆ°u model sau khi huáº¥n luyá»‡n xong
Â Â Â Â await this.saveModel();
Â Â Â Â return {
Â Â Â Â Â Â message: Huáº¥n luyá»‡n Premium Model hoÃ n táº¥t. ÄÃ£ xá»­ lÃ½ ${trainingData.length} chuá»—i, ${EPOCHS} epochs.,
Â Â Â Â Â Â sequences: trainingData.length,
Â Â Â Â Â Â epochs: EPOCHS,
Â Â Â Â Â Â featureSize: this.inputNodes,
Â Â Â Â Â Â modelName: NN_MODEL_NAME
Â Â Â Â };
Â Â }
Â Â async runLearning() {
Â Â console.log('ğŸ”” [TensorFlow Service] Learning from new results...');
Â 
Â Â if (!this.model) {
Â Â Â Â const modelLoaded = await this.loadModel();
Â Â Â Â if (!modelLoaded) {
Â Â Â Â Â Â throw new Error('Model chÆ°a Ä‘Æ°á»£c huáº¥n luyá»‡n. HÃ£y cháº¡y huáº¥n luyá»‡n lá»‹ch sá»­ trÆ°á»›c.');
Â Â Â Â }
Â Â }
Â Â // Láº¥y cÃ¡c dá»± Ä‘oÃ¡n chÆ°a Ä‘Æ°á»£c há»c
Â Â const predictionsToLearn = await NNPrediction.find({ danhDauDaSo: false }).lean();
Â Â if (predictionsToLearn.length === 0) {
Â Â Â Â return { message: 'KhÃ´ng cÃ³ dá»± Ä‘oÃ¡n má»›i nÃ o Ä‘á»ƒ há»c.' };
Â Â }
Â Â const results = await Result.find().sort({ 'ngay': 1 }).lean();
Â Â const grouped = {};
Â Â results.forEach(r => {
Â Â Â Â if (!grouped[r.ngay]) grouped[r.ngay] = [];
Â Â Â Â grouped[r.ngay].push(r);
Â Â });
Â Â const days = Object.keys(grouped).sort((a, b) => this.dateKey(a).localeCompare(this.dateKey(b)));
Â 
Â Â let learnedCount = 0;
Â Â const trainingData = [];
Â Â for (const pred of predictionsToLearn) {
Â Â Â Â const targetDayStr = pred.ngayDuDoan;
Â Â Â Â const targetDayIndex = days.indexOf(targetDayStr);
Â Â Â Â if (targetDayIndex >= SEQUENCE_LENGTH) {
Â Â Â Â Â Â const actualResult = (grouped[targetDayStr] || []).find(r => r.giai === 'ÄB');
Â Â Â Â Â 
Â Â Â Â Â Â if (actualResult?.so && String(actualResult.so).length >= 5) {
Â Â Â Â Â Â Â Â // Láº¥y chuá»—i input
Â Â Â Â Â Â Â Â const sequenceDays = days.slice(targetDayIndex - SEQUENCE_LENGTH, targetDayIndex);
Â Â Â Â Â Â Â Â const previousDays = [];
Â Â Â Â Â Â Â Â const inputSequence = sequenceDays.map(day => {
Â Â Â Â Â Â Â Â Â Â const dayResults = grouped[day] || [];
Â Â Â Â Â Â Â Â Â Â const prevDays = previousDays.slice();
Â Â Â Â Â Â Â Â Â Â previousDays.push(dayResults);
Â Â Â Â Â Â Â Â Â Â return this.featureService.extractAllFeatures(dayResults, prevDays, day);
Â Â Â Â Â Â Â Â });
Â Â Â Â Â Â Â Â // Láº¥y target
Â Â Â Â Â Â Â Â const targetGDBString = String(actualResult.so).padStart(5, '0');
Â Â Â Â Â Â Â Â const targetArray = this.prepareTarget(targetGDBString);
Â Â Â Â Â Â Â 
Â Â Â Â Â Â Â Â trainingData.push({ inputSequence, targetArray });
Â Â Â Â Â Â Â Â learnedCount++;
Â Â Â Â Â Â }
Â Â Â Â }
Â Â Â Â // ÄÃ¡nh dáº¥u Ä‘Ã£ há»c
Â Â Â Â await NNPrediction.updateOne({ _id: pred._id }, { danhDauDaSo: true });
Â Â }
Â Â if (trainingData.length > 0) {
Â Â Â Â const inputs = trainingData.map(d => d.inputSequence);
Â Â Â Â const targets = trainingData.map(d => d.targetArray);
Â Â Â Â // Huáº¥n luyá»‡n thÃªm vá»›i dá»¯ liá»‡u má»›i
Â Â Â Â const inputTensor = tf.tensor3d(inputs, [inputs.length, SEQUENCE_LENGTH, this.inputNodes]);
Â Â Â Â const targetTensor = tf.tensor2d(targets, [targets.length, OUTPUT_NODES]);
Â Â Â Â await this.model.fit(inputTensor, targetTensor, {
Â Â Â Â Â Â epochs: 3, // Sá»‘ epoch Ã­t hÆ¡n Ä‘á»ƒ há»c nhanh
Â Â Â Â Â Â batchSize: Math.min(BATCH_SIZE, inputs.length),
Â Â Â Â Â Â validationSplit: 0.1
Â Â Â Â });
Â Â Â Â inputTensor.dispose();
Â Â Â Â targetTensor.dispose();
Â Â Â Â await this.saveModel();
Â Â }
Â 
Â Â return { message: TensorFlow LSTM Ä‘Ã£ há»c xong. ÄÃ£ xá»­ lÃ½ ${learnedCount} káº¿t quáº£ má»›i. };
}
Â Â async runNextDayPrediction() {
Â Â Â Â console.log('ğŸ”” [TensorFlow Service] Generating next day prediction...');
Â Â Â 
Â Â Â Â if (!this.model) {
Â Â Â Â Â Â const modelLoaded = await this.loadModel();
Â Â Â Â Â Â if (!modelLoaded) {
Â Â Â Â Â Â Â Â throw new Error('Model chÆ°a Ä‘Æ°á»£c huáº¥n luyá»‡n. HÃ£y cháº¡y huáº¥n luyá»‡n trÆ°á»›c.');
Â Â Â Â Â Â }
Â Â Â Â }
Â Â Â Â const results = await Result.find().lean();
Â Â Â Â if (results.length < SEQUENCE_LENGTH) {
Â Â Â Â Â Â throw new Error(KhÃ´ng Ä‘á»§ dá»¯ liá»‡u. Cáº§n Ã­t nháº¥t ${SEQUENCE_LENGTH} ngÃ y.);
Â Â Â Â }
Â Â Â Â const grouped = {};
Â Â Â Â results.forEach(r => {
Â Â Â Â Â Â if (!grouped[r.ngay]) grouped[r.ngay] = [];
Â Â Â Â Â Â grouped[r.ngay].push(r);
Â Â Â Â });
Â Â Â Â const days = Object.keys(grouped).sort((a, b) => this.dateKey(a).localeCompare(this.dateKey(b)));
Â Â Â Â const latestSequenceDays = days.slice(-SEQUENCE_LENGTH);
Â Â Â Â const previousDays = [];
Â Â Â Â const inputSequence = latestSequenceDays.map(day => {
Â Â Â Â Â Â const dayResults = grouped[day] || [];
Â Â Â Â Â Â const prevDays = previousDays.slice();
Â Â Â Â Â Â previousDays.push(dayResults);
Â Â Â Â Â Â return this.featureService.extractAllFeatures(dayResults, prevDays, day);
Â Â Â Â });
Â Â Â Â const output = await this.predict(inputSequence);
Â Â Â Â const prediction = this.decodeOutput(output);
Â Â Â Â const latestDay = latestSequenceDays[latestSequenceDays.length - 1];
Â Â Â Â const nextDayStr = DateTime.fromFormat(latestDay, 'dd/MM/yyyy').plus({ days: 1 }).toFormat('dd/MM/yyyy');
Â Â Â Â await NNPrediction.findOneAndUpdate(
Â Â Â Â Â Â { ngayDuDoan: nextDayStr },
Â Â Â Â Â Â { ngayDuDoan: nextDayStr, ...prediction, danhDauDaSo: false },
Â Â Â Â Â Â { upsert: true, new: true }
Â Â Â Â );
Â Â Â Â return {
Â Â Â Â Â Â message: TensorFlow LSTM Ä‘Ã£ táº¡o dá»± Ä‘oÃ¡n cho ngÃ y ${nextDayStr}.,
Â Â Â Â Â Â ngayDuDoan: nextDayStr
Â Â Â Â };
Â Â }
Â Â decodeOutput(output) {
Â Â Â Â const prediction = { pos1: [], pos2: [], pos3: [], pos4: [], pos5: [] };
Â Â Â Â for (let i = 0; i < 5; i++) {
Â Â Â Â Â Â const positionOutput = output.slice(i * 10, (i + 1) * 10);
Â Â Â Â Â Â const digitsWithValues = positionOutput
Â Â Â Â Â Â Â Â .map((value, index) => ({ digit: String(index), value }))
Â Â Â Â Â Â Â Â .sort((a, b) => b.value - a.value)
Â Â Â Â Â Â Â Â .slice(0, 5)
Â Â Â Â Â Â Â Â .map(item => item.digit);
Â Â Â Â Â Â prediction[pos${i + 1}] = digitsWithValues;
Â Â Â Â }
Â Â Â Â return prediction;
Â Â }
}
module.exports = TensorFlowService;
