const tf = require('@tensorflow/tfjs-node');
const { Storage } = require('@google-cloud/storage');
const Result = require('../models/Result');
const NNPrediction = require('../models/NNPrediction');
const NNState = require('../models/NNState');
const FeatureEngineeringService = require('./featureEngineeringService');
const AdvancedFeatureEngineer = require('./advancedFeatureService');
const { DateTime } = require('luxon');

// --- C·∫•u h√¨nh GCS (Gi·ªØ nguy√™n) ---
const gcsCredentialsJSON = process.env.GCS_CREDENTIALS;
const bucketName = process.env.GCS_BUCKET_NAME;
let storage, bucket;
if (gcsCredentialsJSON && bucketName) {
    try {
        const credentials = JSON.parse(gcsCredentialsJSON);
        storage = new Storage({ credentials, projectId: credentials.project_id });
        bucket = storage.bucket(bucketName);
        console.log(`‚úÖ [GCS] ƒê√£ kh·ªüi t·∫°o GCS cho Actor-Critic Service.`);
    } catch (error) { console.error("‚ùå [GCS] L·ªói kh·ªüi t·∫°o GCS.", error); process.exit(1); }
} else {
    console.warn("‚ö†Ô∏è [GCS] C·∫£nh b√°o: Bi·∫øn m√¥i tr∆∞·ªùng GCS ch∆∞a ƒë∆∞·ª£c thi·∫øt l·∫≠p.");
}

// --- C√°c H·∫±ng S·ªë ---
const ACTOR_MODEL_NAME = 'AC_ACTOR_V2'; // N√¢ng c·∫•p phi√™n b·∫£n
const CRITIC_MODEL_NAME = 'AC_CRITIC_V2';
const SEQUENCE_LENGTH = 7;
const FEATURE_SIZE = 346;
const STATE_SHAPE = [SEQUENCE_LENGTH, FEATURE_SIZE];
const OUTPUT_NODES = 50;
const GAMMA = 0.99;
const ACTOR_LR = 0.0001;
const CRITIC_LR = 0.0005;

// --- Custom GCS IO Handler (Gi·ªØ nguy√™n) ---
const getGcsIoHandler = (modelPath) => {
    if (!bucket) throw new Error("GCS Bucket ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o.");
    const modelJsonPath = `${modelPath}/model.json`;
    const weightsBinPath = `${modelPath}/weights.bin`;
    return {
        save: async (modelArtifacts) => {
            const weightsBuffer = Buffer.from(modelArtifacts.weightData);
            await Promise.all([
                bucket.file(modelJsonPath).save(JSON.stringify(modelArtifacts.modelTopology)),
                bucket.file(weightsBinPath).save(weightsBuffer)
            ]);
            return { modelArtifactsInfo: { dateSaved: new Date() } };
        },
        load: async () => {
            const [modelJsonFile, weightsBinFile] = await Promise.all([
                bucket.file(modelJsonPath).download(),
                bucket.file(weightsBinPath).download()
            ]);
            const modelTopology = JSON.parse(modelJsonFile[0].toString());
            const weightData = weightsBinFile[0].buffer;
            return { modelTopology, weightData };
        }
    };
};

class ActorCriticService {
    constructor() {
        this.actor = null;
        this.critic = null;
        this.inputNodes = FEATURE_SIZE;
        this.featureService = new FeatureEngineeringService();
        this.advancedFeatureEngineer = new AdvancedFeatureEngineer();
        this.isInitialized = false;
        // Kh·ªüi t·∫°o optimizers m·ªôt l·∫ßn
        this.actorOptimizer = tf.train.adam(ACTOR_LR);
        this.criticOptimizer = tf.train.adam(CRITIC_LR);
    }

    // =================================================================
    // 1. H√ÄM HU·∫§N LUY·ªÜN L·ªäCH S·ª¨ (ƒê√É N√ÇNG C·∫§P HO√ÄN TO√ÄN)
    // =================================================================
    /**
     * N√ÇNG C·∫§P: Ch·∫°y m·ªôt l·∫ßn duy nh·∫•t ƒë·ªÉ hu·∫•n luy·ªán t·ª´ ƒë·∫ßu v√† t·∫°o to√†n b·ªô l·ªãch s·ª≠.
     * Qu√° tr√¨nh n√†y m√¥ ph·ªèng vi·ªác AI s·ªëng l·∫°i qu√° kh·ª©, d·ª± ƒëo√°n v√† h·ªçc h·ªèi m·ªói ng√†y.
     */
    async runHistoricalTraining() {
        console.log("üïê [AC Train] B·∫Øt ƒë·∫ßu qu√° tr√¨nh Hu·∫•n luy·ªán & T·∫°o L·ªãch s·ª≠ Tu·∫ßn t·ª±...");
        this.buildActor();
        this.buildCritic();

        const allResults = await Result.find().sort({ 'ngay': 1 }).lean();
        if (allResults.length < SEQUENCE_LENGTH + 1) {
            throw new Error("Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ b·∫Øt ƒë·∫ßu hu·∫•n luy·ªán.");
        }

        const grouped = {};
        allResults.forEach(r => { if (!grouped[r.ngay]) grouped[r.ngay] = []; grouped[r.ngay].push(r); });
        const days = Object.keys(grouped).sort((a, b) => this.dateKey(a).localeCompare(this.dateKey(b)));
        
        let createdCount = 0;
        const totalDaysToProcess = days.length - SEQUENCE_LENGTH;

        // V√≤ng l·∫∑p ch√≠nh: "S·ªëng" l·∫°i t·ª´ng ng√†y trong qu√° kh·ª©
        for (let i = SEQUENCE_LENGTH; i < days.length; i++) {
            const currentDate = days[i];
            const previousDate = days[i-1];
            
            // a. Chu·∫©n b·ªã state cho ng√†y h√¥m tr∆∞·ªõc
            const state = this.getStateFromDays(days.slice(i - SEQUENCE_LENGTH, i), grouped);

            // b. D·ª∞ ƒêO√ÅN cho ng√†y hi·ªán t·∫°i
            const actionProbsTensor = tf.tidy(() => this.actor.predict(tf.tensor3d([state], [1, ...STATE_SHAPE])));
            const actionProbs = await actionProbsTensor.data();
            actionProbsTensor.dispose();
            
            const prediction = this.decodeOutput(actionProbs);
            await NNPrediction.findOneAndUpdate({ ngayDuDoan: currentDate }, { ...prediction, danhDauDaSo: true }, { upsert: true });
            createdCount++;

            // c. H·ªåC H·ªéI t·ª´ k·∫øt qu·∫£ c·ªßa ng√†y h√¥m tr∆∞·ªõc
            const actualResultDoc = (grouped[previousDate] || []).find(r => r.giai === 'ƒêB');
            if (actualResultDoc) {
                const prevState = this.getStateFromDays(days.slice(i - 1 - SEQUENCE_LENGTH, i - 1), grouped);
                const prevPrediction = await NNPrediction.findOne({ ngayDuDoan: previousDate }).lean();
                
                if (prevState && prevPrediction) {
                    const actualGDBString = String(actualResultDoc.so).padStart(5, '0');
                    const reward = this.calculateReward(prevPrediction, actualGDBString);
                    const action = this.getActionFromGDB(actualGDBString);

                    // Th·ª±c hi·ªán 1 b∆∞·ªõc h·ªçc
                    await this.learnFromSingleStep(prevState, action, reward, state);
                }
            }
            console.log(`...[AC Train] ƒê√£ x·ª≠ l√Ω ng√†y ${currentDate} (${createdCount}/${totalDaysToProcess})`);
        }
        
        await this.saveModels();
        this.isInitialized = true;
        return { message: `Hu·∫•n luy·ªán & t·∫°o l·ªãch s·ª≠ tu·∫ßn t·ª± ho√†n t·∫•t. ƒê√£ x·ª≠ l√Ω ${createdCount} ng√†y.` };
    }

    // =================================================================
    // 2. C√ÅC H√ÄM C·ªêT L√ïI C·ª¶A RL
    // =================================================================
    
    /**
     * Th·ª±c hi·ªán M·ªòT b∆∞·ªõc c·∫≠p nh·∫≠t tr·ªçng s·ªë cho Actor v√† Critic.
     */
    async learnFromSingleStep(state, action, reward, nextState) {
        const stateTensor = tf.tensor3d([state], [1, ...STATE_SHAPE]);
        const nextStateTensor = tf.tensor3d([nextState], [1, ...STATE_SHAPE]);
        const actionTensor = tf.tensor1d(action, 'int32');

        await tf.tidy(async () => {
            // C·∫≠p nh·∫≠t Critic
            const criticGrads = tf.variableGrads(() => tf.tidy(() => {
                const value = this.critic.apply(stateTensor);
                const nextValue = this.critic.apply(nextStateTensor);
                const tdTarget = tf.scalar(reward).add(nextValue.mul(tf.scalar(GAMMA)));
                return tf.losses.meanSquaredError(tdTarget, value);
            }));
            this.criticOptimizer.applyGradients(criticGrads.grads);

            // C·∫≠p nh·∫≠t Actor
            const advantage = tf.tidy(() => {
                const value = this.critic.predict(stateTensor);
                const nextValue = this.critic.predict(nextStateTensor);
                const tdTarget = tf.scalar(reward).add(nextValue.mul(tf.scalar(GAMMA)));
                return tdTarget.sub(value).detach();
            });

            const actorGrads = tf.variableGrads(() => tf.tidy(() => {
                const policy = this.actor.apply(stateTensor).squeeze();
                const logProb = tf.log(policy.gather(actionTensor));
                return logProb.mul(advantage).mul(tf.scalar(-1)).mean();
            }));
            this.actorOptimizer.applyGradients(actorGrads.grads);
        });

        // D·ªçn d·∫πp tensor
        stateTensor.dispose();
        nextStateTensor.dispose();
        actionTensor.dispose();
    }
    
    /**
     * S·ª¨A L·ªñI: Thu th·∫≠p duy nh·∫•t 1 t·∫≠p ƒë·ªÉ h·ªçc cho ng√†y m·ªõi nh·∫•t.
     */
    async collectEpisodes() {
        const predictionToLearn = await NNPrediction.findOne({ danhDauDaSo: false }).sort({_id: -1}).lean();
        if (!predictionToLearn) return [];

        const date = predictionToLearn.ngayDuDoan;
        console.log(`...[AC Learn] B·∫Øt ƒë·∫ßu thu th·∫≠p t·∫≠p cho ng√†y ${date}...`);

        const results = await Result.find().sort({ 'ngay': 1 }).lean();
        const grouped = {};
        results.forEach(r => { if (!grouped[r.ngay]) grouped[r.ngay] = []; grouped[r.ngay].push(r); });
        const days = Object.keys(grouped).sort((a,b) => this.dateKey(a).localeCompare(this.dateKey(b)));
        
        const dateIndex = days.indexOf(date);
        if (dateIndex < SEQUENCE_LENGTH) return [];
        
        const actualResultDoc = (grouped[date] || []).find(r => r.giai === 'ƒêB');
        if (!actualResultDoc?.so || String(actualResultDoc.so).length < 5) return [];

        const state = this.getStateFromDays(days.slice(dateIndex - SEQUENCE_LENGTH, dateIndex), grouped);
        const nextState = this.getStateFromDays(days.slice(dateIndex - SEQUENCE_LENGTH + 1, dateIndex + 1), grouped);
        const actualGDBString = String(actualResultDoc.so).padStart(5, '0');
        const reward = this.calculateReward(predictionToLearn, actualGDBString);
        const action = this.getActionFromGDB(actualGDBString);
        
        return [{ state, action, reward, nextState, date }];
    }

    // =================================================================
    // 3. C√ÅC H√ÄM C√îNG KHAI KH√ÅC
    // =================================================================
    
    async runLearning() {
        if (!this.isInitialized) {
            const loaded = await this.loadModels();
            if (!loaded) throw new Error("Models not trained. Please run historical training first.");
        }
        
        console.log("üîî [AC Learn] Starting Reinforcement Learning loop for new results...");
        const episodes = await this.collectEpisodes();
        if (episodes.length === 0) {
            await NNPrediction.updateMany({ danhDauDaSo: false }, { danhDauDaSo: true });
            return { message: "Kh√¥ng c√≥ d·ªØ li·ªáu m·ªõi h·ª£p l·ªá ƒë·ªÉ h·ªçc." };
        }

        for (const episode of episodes) {
            await this.learnFromSingleStep(episode.state, episode.action, episode.reward, episode.nextState);
            console.log(`...[AC Learn] Learned from episode on ${episode.date}.`);
        }
        
        await this.saveModels();
        await NNPrediction.updateMany({ danhDauDaSo: false }, { danhDauDaSo: true });
        return { message: `RL training complete. Learned from ${episodes.length} episodes.` };
    }

    async runNextDayPrediction() {
        if (!this.isInitialized) {
            const loaded = await this.loadModels();
            if (!loaded) throw new Error("Models not trained.");
        }
        
        const inputSequence = await this.preparePredictionInput();
        
        const actionProbsTensor = tf.tidy(() => this.actor.predict(tf.tensor3d([inputSequence], [1, ...STATE_SHAPE])));
        const output = await actionProbsTensor.data();
        actionProbsTensor.dispose();
        
        const prediction = this.decodeOutput(output);
        
        const results = await Result.find().sort({_id: -1}).limit(1).lean();
        const latestDay = results[0].ngay;
        const nextDayStr = DateTime.fromFormat(latestDay, 'dd/MM/yyyy').plus({ days: 1 }).toFormat('dd/MM/yyyy');

        await NNPrediction.findOneAndUpdate(
            { ngayDuDoan: nextDayStr },
            { ...prediction, danhDauDaSo: false },
            { upsert: true, new: true }
        );

        return { message: "Prediction generated by Actor-Critic model.", ngayDuDoan: nextDayStr };
    }
    // =================================================================
    // 1. X√ÇY D·ª∞NG & L∆ØU/T·∫¢I M√î H√åNH
    // =================================================================
    buildActor() {
        const model = tf.sequential();
        model.add(tf.layers.lstm({ units: 64, inputShape: STATE_SHAPE, returnSequences: false }));
        model.add(tf.layers.dense({ units: 32, activation: 'relu' }));
        model.add(tf.layers.dense({ units: OUTPUT_NODES, activation: 'softmax' }));
        this.actor = model;
        console.log("‚úÖ Actor model built.");
    }

    buildCritic() {
        const model = tf.sequential();
        model.add(tf.layers.lstm({ units: 64, inputShape: STATE_SHAPE, returnSequences: false }));
        model.add(tf.layers.dense({ units: 32, activation: 'relu' }));
        model.add(tf.layers.dense({ units: 1, activation: 'tanh' }));
        this.critic = model;
        console.log("‚úÖ Critic model built.");
    }
    
    async saveModels() {
        if (!this.actor || !this.critic) throw new Error("Models not built.");
        console.log("üíæ [AC Save] Saving Actor and Critic models to GCS...");
        await Promise.all([
            this.actor.save(getGcsIoHandler(`models/${ACTOR_MODEL_NAME}`)),
            this.critic.save(getGcsIoHandler(`models/${CRITIC_MODEL_NAME}`))
        ]);
        await NNState.findOneAndUpdate(
            { modelName: ACTOR_MODEL_NAME },
            { state: { savedAt: new Date(), gcsPath: `gs://${bucketName}/models/${ACTOR_MODEL_NAME}` } },
            { upsert: true }
        );
        console.log("‚úÖ [AC Save] Models saved successfully.");
    }

    async loadModels() {
        try {
            console.log("üîç [AC Load] Loading Actor and Critic models from GCS...");
            const [actor, critic] = await Promise.all([
                tf.loadLayersModel(getGcsIoHandler(`models/${ACTOR_MODEL_NAME}`)),
                tf.loadLayersModel(getGcsIoHandler(`models/${CRITIC_MODEL_NAME}`))
            ]);
            this.actor = actor;
            this.critic = critic;
            this.isInitialized = true;
            console.log("‚úÖ [AC Load] Models loaded successfully.");
            return true;
        } catch (error) {
            console.log("‚ùå [AC Load] Could not load models. Need training.", error.message);
            return false;
        }
    }
    
    // =================================================================
    // 2. QUY TR√åNH H·ªåC TƒÇNG C∆Ø·ªúNG
    // =================================================================
    async runLearning() {
        if (!this.isInitialized) {
            const loaded = await this.loadModels();
            if (!loaded) throw new Error("Models not trained. Please run historical training first.");
        }
        
        console.log("üîî [AC Learn] Starting Reinforcement Learning loop...");
        const episodes = await this.collectEpisodes();
        if (episodes.length === 0) {
            await NNPrediction.updateMany({ danhDauDaSo: false }, { danhDauDaSo: true });
            return { message: "Kh√¥ng c√≥ d·ªØ li·ªáu m·ªõi h·ª£p l·ªá ƒë·ªÉ h·ªçc." };
        }

        const actorOptimizer = tf.train.adam(ACTOR_LR);
        const criticOptimizer = tf.train.adam(CRITIC_LR);

        for (const episode of episodes) {
            const { state, action, reward, nextState, date } = episode;

            const stateTensor = tf.tensor3d([state], [1, ...STATE_SHAPE]);
            const nextStateTensor = tf.tensor3d([nextState], [1, ...STATE_SHAPE]);
            
            await tf.tidy(async () => {
                // --- C·∫≠p nh·∫≠t Critic ---
                const criticGrads = tf.variableGrads(() => tf.tidy(() => {
                    const value = this.critic.apply(stateTensor);
                    const nextValue = this.critic.apply(nextStateTensor);
                    const tdTarget = tf.scalar(reward).add(nextValue.mul(tf.scalar(GAMMA)));
                    const tdError = tdTarget.sub(value);
                    return tdError.square().mean();
                }));
                criticOptimizer.applyGradients(criticGrads.grads);
                tf.dispose(criticGrads.grads);

                // --- C·∫≠p nh·∫≠t Actor ---
                const advantage = tf.tidy(() => {
                    const value = this.critic.predict(stateTensor);
                    const nextValue = this.critic.predict(nextStateTensor);
                    const tdTarget = tf.scalar(reward).add(nextValue.mul(tf.scalar(GAMMA)));
                    return tdTarget.sub(value).detach();
                });

                const actorGrads = tf.variableGrads(() => tf.tidy(() => {
                    const policy = this.actor.apply(stateTensor);
                    const logProb = tf.log(policy.gather(action, 1));
                    return logProb.mul(advantage).mul(tf.scalar(-1)).mean(); // L·∫•y mean ƒë·ªÉ loss l√† scalar
                }));
                actorOptimizer.applyGradients(actorGrads.grads);
                tf.dispose(actorGrads.grads);
                advantage.dispose();
            });

            stateTensor.dispose();
            nextStateTensor.dispose();
            action.dispose();
            console.log(`...[AC Learn] Learned from episode on ${date}.`);
        }
        
        await this.saveModels();
        await NNPrediction.updateMany({ danhDauDaSo: { $in: episodes.map(e => e.date) } }, { danhDauDaSo: true });
        return { message: `RL training complete. Learned from ${episodes.length} episodes.` };
    }

    // =================================================================
    // 3. HU·∫§N LUY·ªÜN L·ªäCH S·ª¨ & D·ª∞ ƒêO√ÅN
    // =================================================================
    async runHistoricalTraining() {
        console.log("üïê [AC Train] Starting historical pre-training...");
        this.buildActor();
        this.buildCritic();

        const trainingData = await this.prepareHistoricalData();
        if (!trainingData) {
            throw new Error("Kh√¥ng th·ªÉ chu·∫©n b·ªã d·ªØ li·ªáu hu·∫•n luy·ªán l·ªãch s·ª≠.");
        }
        
        const { inputs, actorTargets, criticTargets } = trainingData;

        console.log(`...Training Actor with ${inputs.shape[0]} samples...`);
        this.actor.compile({ optimizer: tf.train.adam(ACTOR_LR), loss: 'categoricalCrossentropy' });
        await this.actor.fit(inputs, actorTargets, { epochs: 30, batchSize: 64, shuffle: true, verbose: 0, callbacks: { onEpochEnd: (e) => console.log(`  Actor Epoch ${e+1}`) } });

        console.log(`...Training Critic with ${inputs.shape[0]} samples...`);
        this.critic.compile({ optimizer: tf.train.adam(CRITIC_LR), loss: 'meanSquaredError' });
        await this.critic.fit(inputs, criticTargets, { epochs: 20, batchSize: 64, shuffle: true, verbose: 0, callbacks: { onEpochEnd: (e) => console.log(`  Critic Epoch ${e+1}`) } });
        
        inputs.dispose();
        actorTargets.dispose();
        criticTargets.dispose();

        await this.saveModels();
        this.isInitialized = true;
        return { message: "Actor-Critic models pre-trained successfully." };
    }

    async runNextDayPrediction() {
        if (!this.isInitialized) {
            const loaded = await this.loadModels();
            if (!loaded) throw new Error("Models not trained.");
        }
        
        const inputSequence = await this.preparePredictionInput();
        
        const actionProbsTensor = tf.tidy(() => this.actor.predict(tf.tensor3d([inputSequence], [1, ...STATE_SHAPE])));
        const output = await actionProbsTensor.data();
        actionProbsTensor.dispose();
        
        const prediction = this.decodeOutput(output);
        
        const results = await Result.find().sort({_id: -1}).limit(1).lean();
        const latestDay = results[0].ngay;
        const nextDayStr = DateTime.fromFormat(latestDay, 'dd/MM/yyyy').plus({ days: 1 }).toFormat('dd/MM/yyyy');

        await NNPrediction.findOneAndUpdate(
            { ngayDuDoan: nextDayStr },
            { ngayDuDoan: nextDayStr, ...prediction, danhDauDaSo: false },
            { upsert: true, new: true }
        );

        return { message: "Prediction generated by Actor-Critic model.", ngayDuDoan: nextDayStr };
    }

    // =================================================================
    // 4. C√ÅC H√ÄM HELPER (HO√ÄN CH·ªàNH)
    // =================================================================
    dateKey(s) {
        if (!s) return '';
        const parts = s.split('/');
        return parts.length !== 3 ? s : `${parts[2]}-${parts[1].padStart(2, '0')}-${parts[0].padStart(2, '0')}`;
    }

    getStateFromDays(days, groupedData) {
        return days.map(day => this.getFeatureVectorForDay(groupedData[day] || [], [], day));
    }

    
 getFeatureVectorForDay(dayResults, previousDaysData, dateStr) {
        // H√†m n√†y c√≥ th·ªÉ r·∫•t ph·ª©c t·∫°p, t·∫°m th·ªùi ƒë∆°n gi·∫£n h√≥a
        const features = Array(FEATURE_SIZE).fill(0);
        if(dayResults.length > 0) {
            const gdb = dayResults.find(r => r.giai === 'ƒêB');
            if (gdb && gdb.so) {
                const digits = String(gdb.so).padStart(5,'0').split('').map(Number);
                digits.forEach((d,i) => features[i] = d / 9.0);
            }
        }
        return features;
    }

    calculateReward(prediction, actualGDB) {
        let correctCount = 0;
        if (prediction.pos1.includes(actualGDB[0])) correctCount++;
        if (prediction.pos2.includes(actualGDB[1])) correctCount++;
        if (prediction.pos3.includes(actualGDB[2])) correctCount++;
        if (prediction.pos4.includes(actualGDB[3])) correctCount++;
        if (prediction.pos5.includes(actualGDB[4])) correctCount++;
        
        if (correctCount === 5) return 1.0;
        if (correctCount >= 3) return 0.5;
        if (correctCount > 0) return 0.1;
        return -1.0;
    }

    getActionFromGDB(gdbString) {
        const actionIndices = [];
        for(let i=0; i<5; i++) {
            const digit = parseInt(gdbString[i]);
            actionIndices.push(i * 10 + digit);
        }
        return actionIndices;
    }
    
    async prepareHistoricalData() {
        const results = await Result.find().sort({ 'ngay': 1 }).lean();
        if (results.length < SEQUENCE_LENGTH + 2) return null;

        const grouped = {};
        results.forEach(r => { if (!grouped[r.ngay]) grouped[r.ngay] = []; grouped[r.ngay].push(r); });
        const days = Object.keys(grouped).sort((a, b) => this.dateKey(a).localeCompare(this.dateKey(b)));

        const inputs = [];
        const actorTargets = [];
        const criticTargets = [];

        for (let i = SEQUENCE_LENGTH; i < days.length -1; i++) {
            const stateDays = days.slice(i - SEQUENCE_LENGTH, i);
            const targetDay = days[i];

            const state = stateDays.map(day => this.getFeatureVectorForDay(grouped[day] || [], [], day));
            const targetGDB = (grouped[targetDay] || []).find(r => r.giai === 'ƒêB');

            if (targetGDB?.so && String(targetGDB.so).length >= 5) {
                inputs.push(state);
                const targetGDBString = String(targetGDB.so).padStart(5, '0');
                const actorTarget = this.prepareTarget(targetGDBString);
                actorTargets.push(actorTarget);
                
                // Reward gi·∫£ ƒë·ªãnh cho pre-training: 1.0 cho m·ªçi d·ªØ li·ªáu l·ªãch s·ª≠
                criticTargets.push([1.0]); 
            }
        }
        return {
            inputs: tf.tensor3d(inputs),
            actorTargets: tf.tensor2d(actorTargets),
            criticTargets: tf.tensor2d(criticTargets)
        };
    }
    
    async collectEpisodes() {
        console.log("...[AC Learn] B·∫Øt ƒë·∫ßu thu th·∫≠p c√°c 't·∫≠p' (ng√†y) ƒë·ªÉ h·ªçc...");
        const predictionsToLearn = await NNPrediction.find({ danhDauDaSo: false }).lean();
        if (predictionsToLearn.length === 0) {
            return [];
        }
        
        const results = await Result.find().sort({ 'ngay': 1 }).lean();
        const grouped = {};
        results.forEach(r => { if (!grouped[r.ngay]) grouped[r.ngay] = []; grouped[r.ngay].push(r); });
        const days = Object.keys(grouped).sort((a,b) => this.dateKey(a).localeCompare(this.dateKey(b)));
        
        const episodes = [];

        for (const pred of predictionsToLearn) {
            const date = pred.ngayDuDoan;
            const dateIndex = days.indexOf(date);
            
            if (dateIndex < SEQUENCE_LENGTH || dateIndex >= days.length - 1) {
                console.log(`...B·ªè qua ng√†y ${date}: kh√¥ng ƒë·ªß d·ªØ li·ªáu tr∆∞·ªõc/sau.`);
                continue;
            }
            
            const actualResultDoc = (grouped[date] || []).find(r => r.giai === 'ƒêB');
            if (!actualResultDoc?.so || String(actualResultDoc.so).length < 5) {
                 console.log(`...B·ªè qua ng√†y ${date}: kh√¥ng c√≥ k·∫øt qu·∫£ GƒêB th·ª±c t·∫ø.`);
                continue;
            }

            const stateDays = days.slice(dateIndex - SEQUENCE_LENGTH, dateIndex);
            const state = stateDays.map(d => this.getFeatureVectorForDay(grouped[d] || [], [], d));

            const nextStateDays = days.slice(dateIndex - SEQUENCE_LENGTH + 1, dateIndex + 1);
            const nextState = nextStateDays.map(d => this.getFeatureVectorForDay(grouped[d] || [], [], d));

            const actualGDBString = String(actualResultDoc.so).padStart(5, '0');
            const reward = this.calculateReward(pred, actualGDBString);
            
            const action = tf.tidy(() => {
                const actionIndices = [];
                for(let i=0; i<5; i++) {
                    const digit = parseInt(actualGDBString[i]);
                    actionIndices.push(i * 10 + digit);
                }
                return tf.tensor2d(actionIndices, [5, 1], 'int32');
            });
            
            episodes.push({ state, action, reward, nextState, date });
        }
        
        console.log(`‚úÖ [AC Learn] ƒê√£ thu th·∫≠p th√†nh c√¥ng ${episodes.length} t·∫≠p.`);
        return episodes;
    }

    calculateReward(prediction, actualGDB) {
        let correctCount = 0;
        if (prediction.pos1.includes(actualGDB[0])) correctCount++;
        if (prediction.pos2.includes(actualGDB[1])) correctCount++;
        if (prediction.pos3.includes(actualGDB[2])) correctCount++;
        if (prediction.pos4.includes(actualGDB[3])) correctCount++;
        if (prediction.pos5.includes(actualGDB[4])) correctCount++;
        
        if (correctCount === 5) return 1.0; // Th∆∞·ªüng l·ªõn n·∫øu tr√∫ng c·∫£ 5
        if (correctCount > 0) return 0.5; // Th∆∞·ªüng nh·ªè n·∫øu tr√∫ng 1-4
        return -1.0; // Ph·∫°t n·∫øu tr∆∞·ª£t ho√†n to√†n
    }

    prepareTarget(gdbString) {
        const target = Array(OUTPUT_NODES).fill(0.001); // Small probability for all
        gdbString.split('').forEach((digit, index) => {
            const d = parseInt(digit);
            if (!isNaN(d) && index < 5) {
                target[index * 10 + d] = 0.99; // High probability for correct ones
            }
        });
        return target;
    }
    
    async preparePredictionInput() {
        const results = await Result.find().sort({_id: -1}).lean();
        const grouped = {};
        results.forEach(r => { if (!grouped[r.ngay]) grouped[r.ngay] = []; grouped[r.ngay].push(r); });
        const days = Object.keys(grouped).sort((a, b) => this.dateKey(a).localeCompare(this.dateKey(b)));
        
        if (days.length < SEQUENCE_LENGTH) {
            throw new Error(`Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ t·∫°o input d·ª± ƒëo√°n, ch·ªâ c√≥ ${days.length} ng√†y.`);
        }
        const latestSequenceDays = days.slice(-SEQUENCE_LENGTH);
        return this.getStateFromDays(latestSequenceDays, grouped);
    }

    decodeOutput(output) {
        const prediction = { pos1: [], pos2: [], pos3: [], pos4: [], pos5: [] };
        for (let i = 0; i < 5; i++) {
            const positionOutput = output.slice(i * 10, (i + 1) * 10);
            const digitsWithValues = positionOutput.map((value, index) => ({ digit: String(index), value }))
                .sort((a, b) => b.value - a.value).slice(0, 5).map(item => item.digit);
            prediction[`pos${i + 1}`] = digitsWithValues;
        }
        return prediction;
    }
}

module.exports = ActorCriticService;
