const tf = require('@tensorflow/tfjs');
require('@tensorflow/tfjs-node');
const Result = require('../models/Result');
const NNPrediction = require('../models/NNPrediction');
const NNState = require('../models/NNState');
const { DateTime } = require('luxon');
const FeatureEngineeringService = require('./featureEngineeringService'); // TH√äM D√íNG N√ÄY

class ImprovedLSTMService {
    constructor() {
        this.model = null;
        this.isTrained = false;
        this.inputNodes = 0;
        this.featureService = new FeatureEngineeringService(); // TH√äM D√íNG N√ÄY
    }

    // =================================================================
    // THAY TH·∫æ TO√ÄN B·ªò H√ÄM prepareEnhancedInput C≈®
    // =================================================================
    prepareEnhancedInput(currentDayResults, previousDaysResults = [], dateStr = null) {
        // S·ª¨A: S·ª≠ d·ª•ng featureService thay v√¨ t·ª± t√≠nh to√°n
        return this.featureService.extractAllFeatures(currentDayResults, previousDaysResults, dateStr);
    }

    // =================================================================
    // X√ìA C√ÅC H√ÄM C≈® ƒêI - CH√öNG TA D√ôNG FEATURE SERVICE R·ªíI
    // =================================================================
    // X√ìA: calculateStatisticalFeatures()
    // X√ìA: calculateTemporalFeatures()  
    // X√ìA: calculatePatternFeatures()
    // X√ìA: calculateFrequency()
    // X√ìA: calculateRecency()
    // X√ìA: digitAppearedInDay()

    // =================================================================
    // C·∫¨P NH·∫¨T H√ÄM buildModel ƒê·ªÇ T·ª∞ ƒê·ªòNG T√çNH INPUT_NODES
    // =================================================================
    async buildModel(trainingData) {
        if (!trainingData || trainingData.length === 0) {
            throw new Error('Kh√¥ng c√≥ d·ªØ li·ªáu training ƒë·ªÉ x√°c ƒë·ªãnh k√≠ch th∆∞·ªõc model');
        }

        // T√çNH K√çCH TH∆Ø·ªöC FEATURE VECTOR T·ª™ D·ªÆ LI·ªÜU TH·ª∞C T·∫æ
        const sampleInput = trainingData[0].inputSequence[0];
        this.inputNodes = sampleInput.length;
        const outputNodes = trainingData[0].targetArray.length;

        console.log(`üèóÔ∏è Building LSTM model v·ªõi ${this.inputNodes} input nodes, ${outputNodes} output nodes`);
        
        this.model = tf.sequential({
            layers: [
                tf.layers.lstm({
                    units: 128,
                    returnSequences: true,
                    inputShape: [SEQUENCE_LENGTH, this.inputNodes], // D√ôNG this.inputNodes ƒê·ªòNG
                    dropout: 0.2,
                    recurrentDropout: 0.2
                }),
                tf.layers.lstm({
                    units: 64,
                    dropout: 0.2,
                    recurrentDropout: 0.2
                }),
                tf.layers.dense({
                    units: 32,
                    activation: 'relu'
                }),
                tf.layers.dropout({ rate: 0.3 }),
                tf.layers.dense({
                    units: outputNodes, // D√ôNG outputNodes ƒê·ªòNG
                    activation: 'sigmoid'
                })
            ]
        });

        this.model.compile({
            optimizer: tf.train.adam(0.001),
            loss: 'binaryCrossentropy',
            metrics: ['accuracy', 'precision', 'recall']
        });

        console.log('‚úÖ LSTM model built successfully');
        return this.model;
    }

    // =================================================================
    // C·∫¨P NH·∫¨T H√ÄM runHistoricalTraining
    // =================================================================
    async runHistoricalTraining() {
        console.log('üîî [Improved LSTM] Starting Historical Training...');
        
        // Chu·∫©n b·ªã d·ªØ li·ªáu training TR∆Ø·ªöC
        const trainingData = await this.prepareTrainingData();
        if (!trainingData.length) {
            throw new Error('Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ hu·∫•n luy·ªán');
        }

        console.log(`üìä Feature vector size: ${trainingData[0].inputSequence[0].length} nodes`);
        
        // T·∫£i ho·∫∑c t·∫°o m·ªõi model - TRUY·ªÄN trainingData V√ÄO buildModel
        const modelLoaded = await this.loadModel();
        if (!modelLoaded) {
            await this.buildModel(trainingData); // S·ª¨A: truy·ªÅn trainingData v√†o
        }

        await this.trainModel(trainingData);
        await this.saveModel();

        return { 
            message: `AI (TensorFlow LSTM) ƒë√£ h·ªçc xong. ${trainingData.length} sequences, ${EPOCHS} epochs, Feature size: ${this.inputNodes}`,
            sequences: trainingData.length,
            epochs: EPOCHS,
            featureSize: this.inputNodes
        };
    }

    // =================================================================
    // C·∫¨P NH·∫¨T H√ÄM prepareTrainingData
    // =================================================================
    async prepareTrainingData() {
        const results = await Result.find().sort({ 'ngay': 1 }).lean();
        if (results.length < SEQUENCE_LENGTH + 1) {
            return [];
        }

        const grouped = {};
        results.forEach(r => { 
            if (!grouped[r.ngay]) grouped[r.ngay] = []; 
            grouped[r.ngay].push(r); 
        });

        const days = Object.keys(grouped).sort((a, b) => this.dateKey(a).localeCompare(this.dateKey(b)));
        const trainingData = [];

        for (let i = 0; i < days.length - SEQUENCE_LENGTH; i++) {
            const sequenceDays = days.slice(i, i + SEQUENCE_LENGTH);
            const targetDay = days[i + SEQUENCE_LENGTH];

            // L·∫•y d·ªØ li·ªáu c√°c ng√†y tr∆∞·ªõc ƒë·ªÉ t√≠nh pattern features
            const previousDays = sequenceDays.map(day => grouped[day] || []);
            
            // S·ª¨A: S·ª≠ d·ª•ng prepareEnhancedInput m·ªõi (ƒë√£ t√≠ch h·ª£p featureService)
            const inputSequence = sequenceDays.map((day, idx) => 
                this.prepareEnhancedInput(
                    grouped[day] || [], 
                    previousDays.slice(0, idx), 
                    day // TH√äM dateStr
                )
            );

            const targetGDB = (grouped[targetDay] || []).find(r => r.giai === 'ƒêB');
            if (targetGDB?.so && String(targetGDB.so).length >= 5) {
                const targetGDBString = String(targetGDB.so).padStart(5, '0');
                const targetArray = this.prepareTarget(targetGDBString);
                trainingData.push({ inputSequence, targetArray });
            }
        }

        console.log(`üìà Prepared ${trainingData.length} training sequences v·ªõi feature size: ${trainingData[0]?.inputSequence[0]?.length || 0}`);
        return trainingData;
    }

    // =================================================================
    // C·∫¨P NH·∫¨T H√ÄM loadModel
    // =================================================================
    async loadModel() {
        const modelState = await NNState.findOne({ modelName: NN_MODEL_NAME });
        
        if (!modelState || !modelState.modelArtifacts) {
            console.log('üÜï No saved model found, will create new one after training data preparation');
            return false;
        }

        try {
            this.model = await tf.loadLayersModel('indexeddb://' + NN_MODEL_NAME);
            this.inputNodes = modelState.state.inputNodes || 0;
            this.isTrained = modelState.state.isTrained || false;
            
            console.log(`‚úÖ Model loaded successfully v·ªõi ${this.inputNodes} input nodes`);
            return true;
        } catch (error) {
            console.warn('‚ùå Failed to load saved model, will create new one:', error.message);
            return false;
        }
    }

    // =================================================================
    // C·∫¨P NH·∫¨T H√ÄM saveModel
    // =================================================================
    async saveModel() {
        if (!this.model) {
            throw new Error('No model to save');
        }

        const modelInfo = {
            modelName: NN_MODEL_NAME,
            inputNodes: this.inputNodes, // L∆ØU inputNodes th·ª±c t·∫ø
            isTrained: this.isTrained,
            savedAt: new Date().toISOString(),
            featureService: 'v1' // ƒê√°nh d·∫•u phi√™n b·∫£n feature service
        };

        await NNState.findOneAndUpdate(
            { modelName: NN_MODEL_NAME },
            { 
                state: modelInfo,
                modelArtifacts: await this.model.save('indexeddb://' + NN_MODEL_NAME)
            },
            { upsert: true }
        );

        console.log(`üíæ Model saved v·ªõi ${this.inputNodes} input nodes`);
    }
}
